{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrasing the problem\n",
    "Given $x$, we want $\\hat{y} = P(y = 1 \\mid x)$ where $x \\in \\mathbb{R}^{n_x}$.\n",
    "\n",
    "For a standard layer, we'll have $\\hat{y} = \\sigma(\\omega^Tx + b)$ - a linear transformation with a sigmoid applied to it.\n",
    "\n",
    "The sigmoid function, $\\sigma(x) = \\frac{1}{1+e^{-x}}$. As $x \\rightarrow \\infty$, $\\sigma(x)$ goes to 1; inversely, $\\sigma(x)$ goes to 0 as $x \\rightarrow-\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Loss Function\n",
    "\n",
    "We *could* use the sum of square error:\n",
    "\n",
    "$\\mathcal{L}(\\hat{y}, y) = \\frac{1}{2}(\\hat{y}-y)^2$\n",
    "\n",
    "But this ends up being non-convex, and makes the solution very challenging to arrive at - we get lots of local optima.\n",
    "\n",
    "So what we do use is:\n",
    "\n",
    "$\\mathcal{L}(\\hat{y}, y) = -(y\\log\\hat{y} + (1-y)\\log(1-\\hat{y}))$\n",
    "\n",
    "Now, when $y=1$ - when that's our target, that is - then the second term disappears:\n",
    "\n",
    "$\\mathcal{L}(\\hat{y}, y) = -\\log\\hat{y}$\n",
    "\n",
    "So if $\\hat{y}$ is near 1, this is just about $0$ (that's good for a loss function!) and otherwise it just gets larger and larger as it approaches 0.\n",
    "\n",
    "Likewise, when $y=0$ - when our target is 0 - then the function becomes:\n",
    "\n",
    "$\\mathcal{L}(\\hat{y}, y) = -\\log(1-\\hat{y})$\n",
    "\n",
    "And likewise, as $\\hat{y}$ goes to 1, the term approaches 0 and the loss function gets larger and larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cost Function\n",
    "\n",
    "Very good - now we want to define our cost function, $J(\\omega,b)$:\n",
    "\n",
    "$J(\\omega,b) = \\frac{1}{m}\\sum_{i=1}^{m}\\mathcal{L}(\\hat{y}^i,y^i)$\n",
    "\n",
    "Which is to say, it's the sum across all the samples.\n",
    "\n",
    "The loss function is applied to a **single training example**; the cost function is the **cost of your parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we calculate gradient descent, we start at the end of the function and work our way back.\n",
    "\n",
    "For us, this means that we're starting our loss function and working backwards - and we need to consider this on multiple examples. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
