{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief summary\n",
    "\n",
    "Typically a framework for control problems.\n",
    "\n",
    "You have an **agent** and an **environment**. The agent **acts**, **observes**, and gets a reward or penalty, and updates accordingly.\n",
    "\n",
    "In brief:\n",
    "1. Observe\n",
    "2. Select action using policy\n",
    "3. Takes action\n",
    "4. Gets reward or penalty\n",
    "5. Update policy (learning step)\n",
    "\n",
    "[Ye old Wikipedia link.](https://en.wikipedia.org/wiki/Reinforcement_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cons\n",
    "* It's not sample efficient\n",
    "* It cheats - grey goo problems\n",
    "* [Doesn't work yet.](https://alexirpan.com/2018/02/14/rl-hard.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry applications:\n",
    "\n",
    "* Paul Wighton of [3dimageautomation](3dimageautomation.com.au) is using this in industry.\n",
    "* Prof. Pieter Abbeel is quitting his job to follow it.\n",
    "* Spica.ai\n",
    "* [Beating Sonic the Hedgehog](https://github.com/wassname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Related fields\n",
    "\n",
    "When tying it to supervised and unsupervised: Yann Lecun's cake.\n",
    "\n",
    "Very cross-skilled. Related fields might include:\n",
    "* Bounded rationality\n",
    "* Machine learning\n",
    "* Operations research\n",
    "* Conditioning \n",
    "* Reward systems\n",
    "* Optimal control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related concept: World models\n",
    "\n",
    "Broad concept: \"Wouldn't it be good if the system had some idea about the physics or how the world works before your model took action?\"\n",
    "\n",
    "Controller:\n",
    "\n",
    "* \"RL Algorithms landscape\" - one of use is proximal policy optmisation\n",
    "\n",
    "Subconcepts:\n",
    "* Variable auto-encoders - \"Imagine if someone had to recreate a drawing from a single sentence. What concepts would you choose to write down or encode?\" [A brief introduction.](http://kvfrans.com/variational-autoencoders-explained/)\n",
    "* MDN-RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related concept: Mixture density networks\n",
    "\n",
    "[A quick link.](http://cbonnett.github.io/MDN_EDWARD_KERAS_TF.html)\n",
    "\n",
    "Broad concept: You might have some system - the thing I'm trying to predict isn't gaussian, but maybe it's two (or ten) gaussian models with peaks... (I still have no idea what this means)\n",
    "\n",
    "Related: sketch RNN. Hardmaru released a transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful links and papers\n",
    "\n",
    "[Machine efficient solution of poker.](https://arxiv.org/pdf/1805.09195.pdf)\n",
    "\n",
    "[Style transfer in NLP.](https://t.co/Y9VzvGOHWk) Recently out of Stanford. Previously not done for text.\n",
    "\n",
    "[MDN tutorial](https://github.com/hardmaru/pytorch_notebooks/blob/master/mixture_density_networks.ipynb)\n",
    "\n",
    "Open AI Docker submissions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
