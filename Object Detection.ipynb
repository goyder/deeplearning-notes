{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "\n",
    "We can distinguish between:\n",
    "* Classification\n",
    "* Classification with localisation\n",
    "* Detection.\n",
    "\n",
    "The first two typically have one large image that we want to classify and locate.\n",
    "\n",
    "With detection, we may very well be dealing with multiple detections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure and Outputs\n",
    "\n",
    "To extend a classification problem into a localisation problem, we want four more numerical outputs in addition to the softmax. \n",
    "\n",
    "We want to output $b_x, b_y, b_h, b_w$ - these are the x and y coordinates, and the height and width of the box, respectively. \n",
    "\n",
    "And again, we need to classify the class that we are drawing from.\n",
    "\n",
    "So the target label might end up being:\n",
    "\n",
    "$y = \\begin{bmatrix} p_c \\\\ b_x \\\\ b_y \\\\ b_w \\\\ b_h \\\\ c_1 \\\\ c_2 \\\\ c_3 \\\\ \\end{bmatrix}$\n",
    "\n",
    "where\n",
    "\n",
    "$p_c$ indicates whether we have detection an object, and $c_{<n>}$ indicates what class the object belongs to.\n",
    "\n",
    "In this scenario, our loss function becomes:\n",
    "\n",
    "$ \\mathcal{L}(\\hat{y}, y) =  (\\hat{y}_1 - y_1)^2 + (\\hat{y}_2 - y_2)^2 + ... + (\\hat{y}_8 - y_8)^2 $\n",
    "\n",
    "Although we can, of course, be more specific in how we approch the loss of each set - log likelihood loss for the classification, for example, and logistic for $p_c$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differing approaches\n",
    "\n",
    "While the above is a typical appraoch, there are some variations. Consider the [YOLO](https://arxiv.org/pdf/1506.02640.pdf) (You Only Look Once) approach.\n",
    "\n",
    "For the same approach:\n",
    "\n",
    "$y = \\begin{bmatrix} p_c \\\\ b_x \\\\ b_y \\\\ b_w \\\\ b_h \\\\ c_1 \\\\ c_2 \\\\ c_3 \\\\ \\end{bmatrix}$\n",
    "\n",
    "We now have $b_x$ and $b_y$ referring to the midpoints of hte image, and $b_w$ and $b_h$ defined relative to the width of the cell it is found in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-max suppression\n",
    "\n",
    "It's quite possible that we'll end up with multiple detections of the same object.\n",
    "\n",
    "\n",
    "\n",
    "So first, we'll throw out all boxes with probabilities less than some value (say, 0.6). \n",
    "\n",
    "Then, we'll take the most confident prediction. This is a prediction. We commit to it.\n",
    "\n",
    "Then, discard any remaining box with IoU > 0.5 with the box output in the previous step. \n",
    "\n",
    "We repeat this until we run out of boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Boxes\n",
    "\n",
    "These models may have a struggle with overlapping objects. \n",
    "\n",
    "With a base algorithm, each object in a training image is assigned to a grid cell that contains the object's midpoint.\n",
    "\n",
    "When we use multiple anchor boxes, each object in training is assigned to a grid cell that contains the object's midpoint, *and* to an anchor box for the grid cell the highest IoU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Proposals\n",
    "\n",
    "To avoid running the conv net all over windows that we really don't believe anything to be, we can run region proposals first of all.\n",
    "\n",
    "First, we'll run a segmentation algorithm and classify the area in classes.\n",
    "\n",
    "Then, having split up the image into 'blobs' of classes, we can run a classifer on each 'blob'. \n",
    "\n",
    "A good explanation can be found [here](https://medium.com/@smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
